{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "view-in-github",
    "colab_type": "text"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/ziatdinovmax/atomai/blob/master/examples/notebooks/ImageDenoising.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zMCB-p5LAb3C"
   },
   "source": [
    "# Autoencoders for Image Denoising\n",
    "\n",
    "*  *Notebook prepared by Maxim Ziatdinov  (email: maxim.ziatdinov@gmail.com)*\n",
    "\n",
    "*  *The simulated data (atomic coordinates) comes from MD calculations by Bobby Sumpter and Ayana Ghosh at Oak Ridge National Lab*\n",
    "\n",
    "*  *Experimental data by Ondrej Dyck at Oak ridge National Lab*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "k_6I8y4LAk8B"
   },
   "source": [
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "This notebook provides a simple example of training a denoising Autoencoder for simple image cleaning (denoising) using [AtomAI](https://github.com/pycroscopy/atomai). Generally, autoencoders refer to the class of the neural networks that compress the data set to a small number of bottleneck features, and then expand back to original data size. The training aims to minimize information loss between the initial and reconstructed images via usual backpropagation. This process tends to select the relevant features in the data set and reject the noise, giving rise to applications for denoising.\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AOO4jXNPgqOb"
   },
   "source": [
    "Install AtomAI:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "rD_4eU-L7mBE"
   },
   "source": [
    "!pip install atomai gdown"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nbaDUfFL7nTD"
   },
   "source": [
    "Imports:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "Rne0yIeK7oBH"
   },
   "source": [
    "import atomai_app as aoi\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eG1RQtQGhNps"
   },
   "source": [
    "Define a helper function for preparing data:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "DpO0pn-khSH4"
   },
   "source": [
    "def split_denoising_data(imgdata_noisy, imgdata, test_size=0.2, holdout_size=0.1, random_state=0):\n",
    "\n",
    "    from sklearn.model_selection import train_test_split\n",
    "\n",
    "    # First split: separate holdout set\n",
    "    X_noisy_temp, X_noisy_holdout, X_clean_temp, X_clean_holdout = train_test_split(\n",
    "        imgdata_noisy, imgdata, test_size=holdout_size, random_state=random_state\n",
    "    )\n",
    "\n",
    "    # Second split: train/test from remaining data\n",
    "    relative_test_size = test_size / (1 - holdout_size)\n",
    "    X_noisy_train, X_noisy_test, X_clean_train, X_clean_test = train_test_split(\n",
    "        X_noisy_temp, X_clean_temp, test_size=relative_test_size,\n",
    "        random_state=random_state + 1\n",
    "    )\n",
    "\n",
    "    return (X_noisy_train, X_noisy_test, X_noisy_holdout,\n",
    "            X_clean_train, X_clean_test, X_clean_holdout)\n",
    "\n",
    "\n",
    "def scale_to_training_range(expdata, training_data):\n",
    "    scale_factor = training_data.max() / expdata.max()\n",
    "    return expdata * scale_factor"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DNvSGcWiFNF8"
   },
   "source": [
    "Download simulated data of graphene:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0Uc1U6nxhyU9",
    "outputId": "45f5a564-0604-4176-bb06-3dbaf0cf8571"
   },
   "source": [
    "# Download data\n",
    "!gdown -O \"graphene_MD_imgs.npy\" \"https://drive.google.com/uc?id=1iFZvHKkOLWxPVe6dlm5GTJOSimAZJCMf\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "158aq4XI_1c7"
   },
   "source": [
    "Load data into the notebook:\n"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JGglvEvV_w_4",
    "outputId": "857996e4-3943-4ae2-e511-b543ce8a99b6"
   },
   "source": [
    "imgdata = np.load(\"graphene_MD_imgs.npy\")[::2] # take every 2nd sample\n",
    "print(imgdata.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "om58bowpBPb4"
   },
   "source": [
    "Now let's corrupt our data with noise and then use a denoising autoencoder to reconstruct the original images."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "6-9MFb9o4qWM"
   },
   "source": [
    "np.random.seed(0) # for reproducibility\n",
    "# Add noise to data\n",
    "imgdata_noisy = imgdata + np.random.normal(scale=8, size=imgdata.shape)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ExN0M4CDBUiK"
   },
   "source": [
    "View selected pairs of images (images from the left subplot will be inputs into a neural network and images from the right subplot will be our targets)"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 485
    },
    "id": "UmAt4x2un3WD",
    "outputId": "66ab4db9-2cee-406a-f30c-48c7a05cc9d0"
   },
   "source": [
    "k = 15\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "ax1.imshow(imgdata_noisy[k])\n",
    "ax2.imshow(imgdata[k])\n",
    "ax1.set_title(\"Corrupted image\")\n",
    "ax2.set_title(\"Original image\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3A5W9NibeatE"
   },
   "source": [
    "Split data into train, test, and holdout sets:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "otTc31Qi-HkM"
   },
   "source": [
    "(X_noisy_train, X_noisy_test, X_noisy_holdout,\n",
    " X_clean_train, X_clean_test, X_clean_holdout) = split_denoising_data(imgdata_noisy, imgdata)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i4EOGeiOfvmF"
   },
   "source": [
    "Initialize and train AtomAI's denoiser model:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 854
    },
    "id": "bJTbGndepzzJ",
    "outputId": "a3a5e964-3ce1-461b-93a7-b3c455d66f04"
   },
   "source": [
    "denoiser = aoi.models.DenoisingAutoencoder()\n",
    "denoiser.fit(X_noisy_train, X_clean_train, X_noisy_test, X_clean_test, training_cycles=500)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KJix7f1JfpIl"
   },
   "source": [
    "Make a prediction on the holdout dataset:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "CWNuvUoDq0mf"
   },
   "source": [
    "predictions = denoiser.predict(X_noisy_holdout)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C69X1trQhGIj"
   },
   "source": [
    "Plot results:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 373
    },
    "id": "XBATEMZvrtUA",
    "outputId": "48e448bf-61b8-439e-d48e-44502eb6ce65"
   },
   "source": [
    "k = 5 # select a prediction to plot\n",
    "_, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(12, 5))\n",
    "ax1.imshow(X_noisy_holdout[k])\n",
    "ax2.imshow(predictions[k])\n",
    "ax3.imshow(X_clean_holdout[k] - predictions[k])\n",
    "ax1.set_title(\"Input (test) noisy data\")\n",
    "ax2.set_title(\"Cleaned data\")\n",
    "ax3.set_title(\"Difference\")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vTqxqoP8hAZH"
   },
   "source": [
    "Now we are going to gradually increase the noise level and see how well our model can generalize:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "Ah0dX2xgrxki",
    "outputId": "5e970e5e-22a6-46e2-b2bf-251555304eb4"
   },
   "source": [
    "img = X_noisy_holdout[k]\n",
    "for s in range(0, 100, 5):\n",
    "    img = img + np.random.normal(scale=8+s, size=img.shape)\n",
    "    prediction = denoiser.predict(img)\n",
    "    _, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "    ax1.imshow(img)\n",
    "    ax2.imshow(prediction)\n",
    "    ax1.set_title(\"Input noisy data\")\n",
    "    ax2.set_title(\"Cleaned data\")\n",
    "    plt.show()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b5NPoElbb7xn"
   },
   "source": [
    "Finally, let's apply it to experimental data. Note that the current model is by no means optimized to work with experimental data - we didn't even consider any scale changes. Still, it is interesting to see how it will perform on real-world data."
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4A7TDnjzb2mz",
    "outputId": "bc421351-00c3-4926-9690-964bcd975a1b"
   },
   "source": [
    "# download data\n",
    "!gdown -O \"graphene_exp.npy\" \"https://drive.google.com/uc?id=18U8YHZUbSZj0Q1__zup5-ABrjaEZmiPc\""
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "jAcOeydKb2m0"
   },
   "source": [
    "# Load experimental iamge\n",
    "expdata = np.load(\"graphene_exp.npy\")\n",
    "\n",
    "# Scale it to the range of pixel values used in training data\n",
    "expdata_scaled = scale_to_training_range(expdata, X_noisy_train)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Fa2QIe-mkfVA"
   },
   "source": [
    "Visualize predictions:"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 703
    },
    "id": "EjkeUPfSb2m1",
    "outputId": "73031074-9d1d-4a82-d78d-2308f96b9876"
   },
   "source": [
    "prediction = denoiser.predict(expdata_scaled)\n",
    "\n",
    "_, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 9))\n",
    "ax1.imshow(expdata_scaled)\n",
    "ax2.imshow(prediction.squeeze())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TimAkxWwcTo8"
   },
   "source": [
    "Looks like a decent prediction!"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "provenance": [],
   "include_colab_link": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
